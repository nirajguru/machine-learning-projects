{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirajguru/machine-learning-projects/blob/main/plant-seedlings-classification/CV_Project_Full_Code_Niraj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9VXT5unCaBd"
      },
      "source": [
        "# Introduction to Computer Vision: Plant Seedlings Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZgcS1MyVGZp"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCxSmokWEKUJ"
      },
      "source": [
        "### Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2mC12JhVNGp"
      },
      "source": [
        "In recent times, the field of agriculture has been in urgent need of modernizing, since the amount of manual work people need to put in to check if plants are growing correctly is still highly extensive. Despite several advances in agricultural technology, people working in the agricultural industry still need to have the ability to sort and recognize different plants and weeds, which takes a lot of time and effort in the long term. The potential is ripe for this trillion-dollar industry to be greatly impacted by technological innovations that cut down on the requirement for manual labor, and this is where Artificial Intelligence can actually benefit the workers in this field, as **the time and energy required to identify plant seedlings will be greatly shortened by the use of AI and Deep Learning.** The ability to do so far more efficiently and even more effectively than experienced manual labor, could lead to better crop yields, the freeing up of human inolvement for higher-order agricultural decision making, and in the long term will result in more sustainable environmental practices in agriculture as well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_I9gQJMVWL_"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkD5j4o4VYYQ"
      },
      "source": [
        "The aim of this project is to Build a Convolutional Neural Netowrk to classify plant seedlings into their respective categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZq8uFtOVfnm"
      },
      "source": [
        "### Data Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75fTG3prVjUU"
      },
      "source": [
        "The Aarhus University Signal Processing group, in collaboration with the University of Southern Denmark, has recently released a dataset containing **images of unique plants belonging to 12 different species.**\n",
        "\n",
        "- The dataset can be download from Olympus.\n",
        "- The data file names are:\n",
        "    - images.npy\n",
        "    - Labels.csv\n",
        "- Due to the large volume of data, the images were converted to the images.npy file and the labels are also put into Labels.csv, so that you can work on the data/project seamlessly without having to worry about the high data volume.\n",
        "\n",
        "- The goal of the project is to create a classifier capable of determining a plant's species from an image.\n",
        "\n",
        "**List of Species**\n",
        "\n",
        "- Black-grass\n",
        "- Charlock\n",
        "- Cleavers\n",
        "- Common Chickweed\n",
        "- Common Wheat\n",
        "- Fat Hen\n",
        "- Loose Silky-bent\n",
        "- Maize\n",
        "- Scentless Mayweed\n",
        "- Shepherds Purse\n",
        "- Small-flowered Cranesbill\n",
        "- Sugar beet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9B4COveVqnm"
      },
      "source": [
        "### **Note: Please use GPU runtime on Google Colab to execute the code faster.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqFzmTb0BKKW"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JAkYVkhPb0p7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f11c45b-144f-46e2-a37f-683c77057920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.10 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xgboost 2.1.0 requires nvidia-nccl-cu12; platform_system == \"Linux\" and platform_machine != \"aarch64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.3 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.25.2 which is incompatible.\n",
            "tensorstore 0.1.63 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Installing the libraries with the specified version.\n",
        "!pip install tensorflow==2.15.0 scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==1.5.3 opencv-python==4.8.0.76 -q --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbFXvdwks2iR"
      },
      "source": [
        "**Note**: *After running the above cell, kindly restart the notebook kernel and run all cells sequentially from the start again.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FsytN_Rps2Cz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np                                                                               # Importing numpy for Matrix Operations\n",
        "import pandas as pd                                                                              # Importing pandas to read CSV files\n",
        "import matplotlib.pyplot as plt                                                                  # Importting matplotlib for Plotting and visualizing images\n",
        "import math                                                                                      # Importing math module to perform mathematical operations\n",
        "import cv2                                                                                       # Importing openCV for image processing\n",
        "import seaborn as sns                                                                            # Importing seaborn to plot graphs\n",
        "\n",
        "\n",
        "# Tensorflow modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator                              # Importing the ImageDataGenerator for data augmentation\n",
        "from tensorflow.keras.models import Sequential                                                   # Importing the sequential module to define a sequential model\n",
        "from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D,BatchNormalization # Defining all the layers to build our CNN Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD                                                 # Importing the optimizers which can be used in our model\n",
        "from sklearn import preprocessing                                                                # Importing the preprocessing module to preprocess the data\n",
        "from sklearn.model_selection import train_test_split                                             # Importing train_test_split function to split the data into train and test\n",
        "from sklearn.metrics import confusion_matrix                                                     # Importing confusion_matrix to plot the confusion matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "# Display images using OpenCV\n",
        "from google.colab.patches import cv2_imshow                                                      # Importing cv2_imshow from google.patches to display images\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import random\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq-hAEOAV4aZ"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XztFCIActAb"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run the below code if you are using google colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2q2QUVZtpFb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE84hQU7CSZa"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57vwo75fcXbU"
      },
      "source": [
        "### Understand the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2F57JGGcbzz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYv5uX-MC9KC"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf_sWYNOjDvK"
      },
      "source": [
        "- EDA is an important part of any project involving data.\n",
        "- It is important to investigate and understand the data better before building a model with it.\n",
        "- A few questions have been mentioned below which will help you understand the data better.\n",
        "- A thorough analysis of the data, in addition to the questions mentioned below, should be done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4dZsdgujrtK"
      },
      "source": [
        "1. How are these different category plant images different from each other?\n",
        "2. Is the dataset provided an imbalance? (Check with using bar plots)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxTvixIeBVIq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOvazq-OWpNB"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzpcKHaDWsG7"
      },
      "source": [
        "### Convert the BGR images to RGB images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9u82V2TWsuQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STMonBqiWxM5"
      },
      "source": [
        "### Resize the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pESDU0AEMOFk"
      },
      "source": [
        "As the size of the images is large, it may be computationally expensive to train on these larger images; therefore, it is preferable to reduce the image size from 128 to 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJYZ4IpGkwre"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdsVQb4umB0P"
      },
      "source": [
        "### Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KljdsjFCmJIZ"
      },
      "source": [
        "- Before you proceed to build a model, you need to split the data into train, test, and validation to be able to evaluate the model that you build on the train data\n",
        "- You'll have to encode categorical features and scale the pixel values.\n",
        "- You will build a model using the train data and then check its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQV0unTvM7XM"
      },
      "source": [
        "**Split the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USifnEb_m85i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAJ9B0wKNiY3"
      },
      "source": [
        "### Encode the target labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88OIAwNoEPfx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exJFCDSMNrEG"
      },
      "source": [
        "### Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVUuPJS9OB_U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9_M19L-OLng"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0fnV8yNKmYr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNKUalx8Jcoi"
      },
      "source": [
        "## Model Performance Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_oS4D_AXFqX"
      },
      "source": [
        "**Reducing the Learning Rate:**\n",
        "\n",
        "**Hint**: Use **ReduceLRonPlateau()** function that will be used to decrease the learning rate by some factor, if the loss is not decreasing for some time. This may start decreasing the loss at a smaller learning rate. There is a possibility that the loss may still not decrease. This may lead to executing the learning rate reduction again in an attempt to achieve a lower loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU6vqL67bd5a"
      },
      "source": [
        "### **Data Augmentation**\n",
        "\n",
        "Remember, **data augmentation should not be used in the validation/test data set**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5cgkAz_YKcc"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3MjkGfHYOPn"
      },
      "source": [
        "Comment on the final model you have selected and use the same in the below code to visualize the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IESvQ8UyYLSK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvDkLMO7YIdY"
      },
      "source": [
        "### Visualizing the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iez7QKJBrHvE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg2x8AyJ4oPR"
      },
      "source": [
        "## Actionable Insights and Business Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvq4_6CZYcrv"
      },
      "source": [
        "*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geC4LwwIYfS_"
      },
      "source": [
        "_____"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4ZgcS1MyVGZp",
        "WCxSmokWEKUJ",
        "q_I9gQJMVWL_",
        "aZq8uFtOVfnm",
        "qqFzmTb0BKKW",
        "oq-hAEOAV4aZ",
        "uE84hQU7CSZa",
        "57vwo75fcXbU",
        "EYv5uX-MC9KC",
        "vOvazq-OWpNB",
        "hzpcKHaDWsG7",
        "STMonBqiWxM5",
        "LdsVQb4umB0P",
        "FAJ9B0wKNiY3",
        "exJFCDSMNrEG",
        "d9_M19L-OLng",
        "kNKUalx8Jcoi",
        "A5cgkAz_YKcc",
        "Eg2x8AyJ4oPR"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}